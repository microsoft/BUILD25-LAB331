{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LAB331: Deep Research with LangChain and DeepSeek R1","text":"<p>Welcome to the Azure Deep Research Workshop! In this hands-on workshop, you'll learn how to build an AI-powered research assistant that can conduct comprehensive web research, analyze and synthesize information, and present findings with illustrative images.</p> <p></p>"},{"location":"#what-youll-build","title":"What You'll Build","text":"<p>This workshop will guide you through creating a sophisticated AI research system that leverages Azure OpenAI's powerful reasoning capabilities, web search integration, and a modern responsive UI to deliver comprehensive research results.</p> <p>By the end of this workshop, you'll have built a complete research application that can:</p> <ul> <li>Process research requests with transparent, real-time AI reasoning</li> <li>Conduct multi-stage web research with knowledge gap identification</li> <li>Perform iterative research cycles to build comprehensive knowledge</li> <li>Present findings with a professional UI including relevant images</li> <li>Deploy as a scalable web application with WebSockets for real-time updates</li> </ul>"},{"location":"#workshop-structure","title":"Workshop Structure","text":"<p>The workshop is organized into four labs:</p> <ol> <li>Reasoning &amp; Model Thoughts: Understand how to harness reasoning models and stream their thinking process in real-time</li> <li>Web Research Integration: Integrate web search capabilities with query generation and information synthesis</li> <li>Research Reflection: Implement knowledge gap identification and iterative research cycles</li> <li>Launching Your Researcher: Transform your terminal application into a modern web interface with FastAPI and WebSockets</li> </ol>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>Before starting this workshop, ensure you have:</p> <ul> <li>Python 3.10+ installed on your machine</li> <li>An Azure account with access to Azure OpenAI Service</li> <li>A basic understanding of Python programming</li> <li>Familiarity with web technologies (HTML, CSS, JavaScript)</li> <li>Access to a Tavily API key for web search capability</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To begin the workshop, proceed to the Getting Started section to set up your environment and install the necessary dependencies.</p> <p>Let's start building your AI-powered research assistant!</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This section will help you set up your environment for the Azure Deep Research Workshop.</p>"},{"location":"getting-started/#environment-setup","title":"Environment Setup","text":""},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>Start by cloning the workshop repository:</p> <pre><code>git clone https://github.com/yourusername/deep-research.git\ncd deep-research\n</code></pre>"},{"location":"getting-started/#2-create-a-virtual-environment","title":"2. Create a Virtual Environment","text":"<p>Create and activate a Python virtual environment:</p> WindowsmacOS/Linux <pre><code>python -m venv deep_research\n.\\deep_research\\Scripts\\activate\n</code></pre> <pre><code>python -m venv deep_research\nsource deep_research/bin/activate\n</code></pre>"},{"location":"getting-started/#3-install-required-packages","title":"3. Install Required Packages","text":"<p>Install the necessary Python packages:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>The key packages include: - <code>langchain-azure-ai</code> for Azure OpenAI integration - <code>tavily-python</code> for web search capabilities - <code>rich</code> for terminal formatting and UI - <code>fastapi</code> and <code>uvicorn</code> for the web application - <code>langgraph</code> for structuring the research workflow</p>"},{"location":"getting-started/#4-set-up-azure-openai","title":"4. Set Up Azure OpenAI","text":"<p>To use Azure OpenAI in this workshop, you'll need:</p> <ol> <li>An Azure account with access to Azure OpenAI Service</li> <li>A deployment of the following models:</li> <li>DeepSeek-R1 (used for reasoning and research)</li> <li>GPT-4o (optional, used in the web application)</li> </ol> <p>If you don't have access yet, request it through the Azure OpenAI Service request form.</p>"},{"location":"getting-started/#5-set-up-tavily-api","title":"5. Set Up Tavily API","text":"<p>Register for a Tavily API key to enable web search capabilities. This API is essential for the web research integration in Labs 2 and 3.</p>"},{"location":"getting-started/#6-configure-environment-variables","title":"6. Configure Environment Variables","text":"<p>Create a <code>.env</code> file in the project root with your API keys:</p> <pre><code>AZURE_AI_ENDPOINT=your_azure_openai_endpoint\nAZURE_API_KEY=your_azure_openai_key\nTAVILY_API_KEY=your_tavily_api_key\n</code></pre> <p>These environment variables will be loaded in each lab using the <code>python-dotenv</code> package.</p>"},{"location":"getting-started/#workshop-materials","title":"Workshop Materials","text":"<p>This workshop is designed as a progressive series of labs, each building on the previous one:</p> <ol> <li> <p>Lab 1 (Reasoning &amp; Model Thoughts): Learn how to stream the AI's thinking process in real-time and format final answers as bullet points.</p> </li> <li> <p>Lab 2 (Web Research Integration): Build a basic research system that generates queries, searches the web, and synthesizes the results.</p> </li> <li> <p>Lab 3 (Research Reflection): Extend the research capabilities with knowledge gap identification and iterative research cycles.</p> </li> <li> <p>Lab 4 (Launching Your Researcher): Deploy the research assistant as a web application with FastAPI and WebSockets for real-time updates.</p> </li> </ol> <p>Each lab includes code samples, explanations, and challenges to extend your learning.</p>"},{"location":"getting-started/#navigation","title":"Navigation","text":"<p>Use the navigation menu on the left to move between labs. Each lab includes:</p> <ul> <li>An overview of what you'll learn</li> <li>Prerequisites specific to that lab</li> <li>Detailed instructions with code samples</li> <li>Explanations of key components</li> <li>Challenges to extend your learning</li> <li>Next steps to progress through the workshop</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Once your environment is set up, proceed to Lab 1: Reasoning &amp; Model Thoughts to begin building your research assistant.</p>"},{"location":"lab-1-reasoning-thoughts/","title":"Lab 1: Reasoning &amp; Model Thoughts","text":"<p>In this lab, you'll learn about reasoning models and how to separate and visualize the AI's thinking process from its final output. This approach gives you insight into the model's reasoning and helps create more transparent AI systems.</p>"},{"location":"lab-1-reasoning-thoughts/#understanding-ai-reasoning","title":"Understanding AI Reasoning","text":"<p>Modern large language models like DeepSeek-R1 and GPT-4o have powerful reasoning capabilities, but they often hide their step-by-step thinking. By explicitly encouraging and capturing this thinking process, we can:</p> <ol> <li>Improve the quality of final outputs</li> <li>Debug reasoning errors</li> <li>Build trust through transparency</li> <li>Create educational tools showing \"how\" the AI thinks</li> </ol>"},{"location":"lab-1-reasoning-thoughts/#lab-overview","title":"Lab Overview","text":"<p>In this lab, you'll:</p> <ol> <li>Learn about reasoning techniques in LLMs</li> <li>Create a simple terminal application that shows thinking vs output</li> <li>Use special prompting techniques to encourage step-by-step reasoning</li> <li>Format the thinking and output visually for better user experience</li> <li>See real-time streaming of the model's thoughts as they develop</li> </ol>"},{"location":"lab-1-reasoning-thoughts/#the-code","title":"The Code","text":"<p>The Python application in <code>lab1_reasoning.py</code> demonstrates reasoning with visible thoughts:</p> <pre><code>import os\nimport time\nfrom dotenv import load_dotenv\nfrom typing import Tuple\nfrom langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.prompt import Prompt\nfrom rich.live import Live\n\n# ... abbreviated for clarity ...\n</code></pre> <p>The code creates a terminal-based application that:</p> <ol> <li>Connects to Azure OpenAI using your credentials</li> <li>Takes research questions as input</li> <li>Uses a special system prompt to encourage the model to \"think aloud\"</li> <li>Streams the thinking process in real-time as the model generates it</li> <li>Formats the final answer as bullet points for clarity</li> <li>Presents the results in styled panels</li> </ol>"},{"location":"lab-1-reasoning-thoughts/#key-components","title":"Key Components","text":""},{"location":"lab-1-reasoning-thoughts/#system-prompt","title":"System Prompt","text":"<p>The system prompt instructs the model to show its reasoning:</p> <pre><code>SYSTEM_PROMPT = \"\"\"You are a research assistant that thinks carefully about questions before answering.\n\nWhen you receive a research question, first think about the problem step-by-step.\nPlace all your reasoning and thinking inside &lt;think&gt;...&lt;/think&gt; tags.\n\nAfter thinking, provide your final answer without the thinking tags in bullet points.\nMake sure to include all the important details in your answer.\n\"\"\"\n</code></pre> <p>This prompt: - Establishes the model's role as a research assistant - Provides explicit instructions for structuring output - Uses XML-like tags (<code>&lt;think&gt;...&lt;/think&gt;</code>) to demarcate thinking - Requires bullet points in the final answer for better readability</p>"},{"location":"lab-1-reasoning-thoughts/#real-time-streaming","title":"Real-Time Streaming","text":"<p>The application streams the model's thinking in real-time using the <code>stream_thinking_and_answer</code> function:</p> <pre><code>def stream_thinking_and_answer(stream_generator, title=\"\ud83e\udde0 AI Thinking Process (Live)\"):\n    \"\"\"\n    Stream the AI's thinking and answer in real-time, separating them visually.\n    \"\"\"\n    # Containers for accumulating thoughts and answer\n    accumulated_thoughts = \"\"\n    accumulated_answer = \"\"\n    in_thinking_section = False\n\n    thinking_panel = Panel(\n        Markdown(\"\"),\n        title=title,\n        title_align=\"left\",\n        border_style=\"cyan\",\n        padding=(1, 2),\n        expand=False\n    )\n\n    with Live(thinking_panel, refresh_per_second=4) as live:\n        for chunk in stream_generator:\n            # ... process each token as it arrives ...\n</code></pre> <p>This function: - Creates a live updating panel using Rich's <code>Live</code> context manager  - Processes each token as it comes from the model - Distinguishes between thinking sections and the final answer - Updates the display in real-time with each new token</p>"},{"location":"lab-1-reasoning-thoughts/#running-the-application","title":"Running the Application","text":"<p>To run the application:</p> <ol> <li>Ensure you have the required packages installed:</li> </ol> <pre><code>pip install python-dotenv langchain-azure-ai rich\n</code></pre> <ol> <li>Create a <code>.env</code> file with your Azure OpenAI credentials:</li> </ol> <pre><code>AZURE_AI_ENDPOINT=your_azure_openai_endpoint\nAZURE_API_KEY=your_azure_openai_key\n</code></pre> <ol> <li>Run the script:</li> </ol> <pre><code>python lab1_reasoning.py\n</code></pre> <ol> <li>Enter research questions at the prompt and observe:</li> <li>The model's thinking process streaming live in real-time</li> <li>The final bullet-point answer displayed separately</li> </ol>"},{"location":"lab-1-reasoning-thoughts/#example-usage","title":"Example Usage","text":"<p>When you run the application, you'll see: 1. A prompt asking for your research question 2. A live cyan panel that updates as the model thinks 3. A green panel with the final bullet-point answer</p> <p>Try questions like:</p> <ul> <li>\"What are the environmental impacts of electric vehicles?\"</li> <li>\"How does quantum computing differ from classical computing?\"</li> <li>\"What factors contribute to biodiversity loss in rainforests?\"</li> </ul>"},{"location":"lab-1-reasoning-thoughts/#benefits","title":"Benefits","text":"<p>This approach of streaming reasoning as it happens offers several advantages:</p> <ol> <li>Transparency: Users can see how the model is reasoning step-by-step</li> <li>Engagement: The live updating creates a more dynamic user experience</li> <li>Educational Value: Observe the reasoning patterns of AI in real time</li> <li>Debugging: Identify reasoning flaws as they emerge</li> <li>Trust: The decision-making is no longer a black box</li> </ol>"},{"location":"lab-1-reasoning-thoughts/#lab-challenges","title":"Lab Challenges","text":"<p>Now that you understand the basics, try these challenges:</p> <ol> <li>Modify the System Prompt: Change the prompt to encourage different types of reasoning</li> <li>Enhance the Visualization: Add progress bars or animations to the thinking display</li> <li>Compare Different Models: Test how different models approach the same question</li> <li>Add Error Handling: Improve how the system handles malformed responses or network issues</li> </ol>"},{"location":"lab-1-reasoning-thoughts/#key-takeaways","title":"Key Takeaways","text":"<p>From this lab, you should understand:</p> <ul> <li>How to encourage models to expose their reasoning process</li> <li>Techniques for streaming AI thinking in real-time</li> <li>The value of separating thinking from final outputs</li> <li>How to implement a basic research assistant with visible thinking</li> </ul>"},{"location":"lab-1-reasoning-thoughts/#next-steps","title":"Next Steps","text":"<p>Ready to add web research capabilities to your AI research assistant? Move on to Lab 2: Web Research Integration.</p>"},{"location":"lab-2-web-research/","title":"Lab 2: Web Research Integration","text":"<p>In this lab, you'll learn how to enhance your AI research assistant by integrating web search capabilities. This allows the model to access up-to-date information beyond its training data and provide more accurate and comprehensive research results.</p>"},{"location":"lab-2-web-research/#understanding-web-connected-ai","title":"Understanding Web-Connected AI","text":"<p>While large language models have extensive knowledge, they have two major limitations:</p> <ol> <li>Training Data Cutoff: Models only have knowledge up to their training cutoff date</li> <li>Knowledge Limitations: No model knows everything, especially about niche or emerging topics</li> </ol> <p>By connecting your AI to web search capabilities, you can: - Obtain current information not available during model training - Get authoritative information from reliable sources - Research specialized topics where the model's knowledge may be limited - Find specific data points, statistics, and references</p>"},{"location":"lab-2-web-research/#lab-overview","title":"Lab Overview","text":"<p>In this lab, you'll:</p> <ol> <li>Set up the Tavily API for web search</li> <li>Create a focused research process with web search integration</li> <li>Structure and analyze search results</li> <li>Build a script that performs research with an AI-guided search strategy</li> <li>See real-time streaming of the AI's thinking at each stage of the process</li> </ol>"},{"location":"lab-2-web-research/#the-web-research-process","title":"The Web Research Process","text":"<p>The web research integration involves three key components:</p> <ol> <li>Query Generation: Creating effective search queries based on the research topic</li> <li>Web Search: Retrieving relevant information from external sources</li> <li>Information Synthesis: Integrating the retrieved information into a cohesive summary</li> </ol> <p></p>"},{"location":"lab-2-web-research/#setting-up-tavily-api","title":"Setting Up Tavily API","text":"<p>In this lab, we'll use the Tavily Search API, which provides AI-optimized web search capabilities. </p> <ol> <li>Sign up for a Tavily API key</li> <li>Add your Tavily API key to your <code>.env</code> file:</li> </ol> <pre><code>TAVILY_API_KEY=your_tavily_api_key\n</code></pre>"},{"location":"lab-2-web-research/#the-code","title":"The Code","text":"<p>The Python application in <code>lab2_web_research.py</code> builds on our reasoning model from Lab 1 and adds web search capabilities:</p> <pre><code>import os\nimport json\nimport time\nimport dotenv\nfrom typing import Dict, List, Any, Tuple\nfrom langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom tavily import TavilyClient\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.prompt import Prompt\nfrom rich.progress import Progress, SpinnerColumn, TextColumn\nfrom rich.live import Live\n\n# ... abbreviated for clarity ...\n</code></pre>"},{"location":"lab-2-web-research/#key-components","title":"Key Components","text":""},{"location":"lab-2-web-research/#query-generation","title":"Query Generation","text":"<p>The system first generates an optimal search query based on the research topic:</p> <pre><code>def generate_search_query(research_topic):\n    \"\"\"Generate an effective search query for the research topic.\"\"\"\n    console.print(\"[bold blue]Generating optimal search query...[/]\")\n\n    messages = [\n        SystemMessage(content=QUERY_GENERATION_PROMPT),\n        HumanMessage(content=f\"Research topic: {research_topic}\")\n    ]\n\n    # Stream the model's thinking process\n    console.print(\"\\n[bold]Query Generation Process:[/]\\n\")\n    response_stream = model.stream(messages)\n    thoughts, query = stream_thinking_and_answer(response_stream, \"\ud83d\udd0d Query Generation Thinking\")\n\n    display_panel(f\"**Search Query**: {query}\", \"\ud83d\udd0d Generated Search Query\", \"green\")\n\n    return query\n</code></pre> <p>This function uses a specialized prompt to help the model craft an effective search query, streaming its thinking process in real-time.</p>"},{"location":"lab-2-web-research/#web-search","title":"Web Search","text":"<p>The generated query is used to perform a web search using the Tavily API:</p> <pre><code>def perform_web_search(query):\n    \"\"\"Perform a web search using the Tavily API.\"\"\"\n    console.print(\"\\n[bold blue]Performing web search...[/]\")\n\n    with Progress(\n        SpinnerColumn(),\n        TextColumn(\"[progress.description]{task.description}\"),\n        transient=True,\n    ) as progress:\n        progress.add_task(\"Searching the web...\", total=None)\n        search_results = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n\n    # Display search result snippets\n    console.print(\"\\n[bold]Search Results:[/]\")\n    for i, result in enumerate(search_results[\"results\"], 1):\n        display_panel(\n            f\"**Title**: {result['title']}\\n\\n**Snippet**: {result['content']}\\n\\n**URL**: {result['url']}\",\n            f\"Result {i}\",\n            \"blue\"\n        )\n\n    return search_results\n</code></pre> <p>This retrieves information from the web about the topic and displays snippets of the results.</p>"},{"location":"lab-2-web-research/#information-synthesis","title":"Information Synthesis","text":"<p>The search results are then summarized into a coherent research overview:</p> <pre><code>def summarize_search_results(research_topic, search_results):\n    \"\"\"Summarize the information from search results.\"\"\"\n    console.print(\"\\n[bold blue]Synthesizing information from search results...[/]\")\n\n    # Format search results for the model\n    formatted_results = \"\"\n    for i, result in enumerate(search_results[\"results\"], 1):\n        formatted_results += f\"Source {i}: {result['title']}\\n\"\n        formatted_results += f\"URL: {result['url']}\\n\"\n        formatted_results += f\"Content: {result['content']}\\n\\n\"\n\n    messages = [\n        SystemMessage(content=SUMMARIZATION_PROMPT),\n        HumanMessage(content=f\"Research Topic: {research_topic}\\n\\nSearch Results:\\n{formatted_results}\")\n    ]\n\n    # Stream the model's thinking process for summarization\n    console.print(\"\\n[bold]Summarization Process:[/]\\n\")\n    response_stream = model.stream(messages)\n    thoughts, summary = stream_thinking_and_answer(response_stream, \"\ud83d\udcdd Summarization Thinking\")\n\n    display_panel(summary, \"\ud83d\udcdd Research Summary\", \"green\")\n\n    return summary\n</code></pre> <p>This synthesizes the search results into a comprehensive summary, again streaming the AI's thinking process.</p>"},{"location":"lab-2-web-research/#research-orchestration","title":"Research Orchestration","text":"<p>The <code>conduct_research</code> function ties everything together:</p> <pre><code>def conduct_research(research_topic):\n    \"\"\"Conduct multi-step research on a topic.\"\"\"\n    console.print(f\"[bold]Starting research on: [green]{research_topic}[/green][/]\\n\")\n\n    # Generate search query\n    query = generate_search_query(research_topic)\n\n    # Perform web search\n    search_results = perform_web_search(query)\n\n    # Summarize search results\n    summary = summarize_search_results(research_topic, search_results)\n\n    return summary\n</code></pre> <p>This function orchestrates the complete research process, from query generation to final summary.</p>"},{"location":"lab-2-web-research/#running-the-application","title":"Running the Application","text":"<p>To run the application:</p> <ol> <li>Ensure you have the required packages installed:</li> </ol> <pre><code>pip install python-dotenv langchain-azure-ai tavily-python rich\n</code></pre> <ol> <li>Make sure your <code>.env</code> file includes both Azure OpenAI and Tavily API keys:</li> </ol> <pre><code>AZURE_AI_ENDPOINT=your_azure_openai_endpoint\nAZURE_API_KEY=your_azure_openai_key\nTAVILY_API_KEY=your_tavily_api_key\n</code></pre> <ol> <li>Run the script:</li> </ol> <pre><code>python lab2_web_research.py\n</code></pre> <ol> <li>Enter a research topic and observe the complete research process.</li> </ol>"},{"location":"lab-2-web-research/#example-usage","title":"Example Usage","text":"<p>When you run the application and enter a research topic like \"latest advancements in fusion energy\", you'll see:</p> <ol> <li>The model generating an effective search query with visible thinking</li> <li>Results from the web search with titles and snippets</li> <li>The model synthesizing a summary with visible thinking</li> <li>A final comprehensive research summary</li> </ol>"},{"location":"lab-2-web-research/#lab-challenges","title":"Lab Challenges","text":"<p>Now that you understand web research integration, try these challenges:</p> <ol> <li>Modify the Search Depth: Change the Tavily search parameters to get different results</li> <li>Customize the Prompts: Adjust the prompts to generate different types of summaries</li> <li>Add Image Support: Extend the script to collect and display relevant images from the web</li> <li>Source Citation: Enhance the summary to include proper citations for each piece of information</li> </ol>"},{"location":"lab-2-web-research/#key-takeaways","title":"Key Takeaways","text":"<p>From this lab, you should understand:</p> <ul> <li>How to connect AI models to external knowledge sources</li> <li>Techniques for generating effective search queries</li> <li>Methods for synthesizing information from multiple sources</li> <li>The power of real-time thinking visualization during each stage</li> </ul>"},{"location":"lab-2-web-research/#next-steps","title":"Next Steps","text":"<p>Ready to extend your research assistant with knowledge gap identification and iterative research? Move on to Lab 3: Research Reflection.</p>"},{"location":"lab-3-reflection/","title":"Lab 3: Research Reflection","text":"<p>In this lab, you'll learn how to create a more thorough research system by implementing knowledge gap identification and iterative research cycles. This advanced approach allows your research assistant to identify what it doesn't know and conduct follow-up research to create more comprehensive results.</p>"},{"location":"lab-3-reflection/#understanding-research-reflection","title":"Understanding Research Reflection","text":"<p>Even with web search capabilities, a single research cycle often leaves important questions unanswered. Real research is iterative - findings from initial searches reveal what else we need to know.</p> <p>Research reflection involves:</p> <ol> <li>Knowledge Gap Identification: Analyzing current information to find what's missing</li> <li>Follow-up Query Generation: Creating targeted follow-up questions to fill these gaps</li> <li>Multiple Research Cycles: Conducting iterative research to build comprehensive knowledge</li> <li>Progressive Synthesis: Combining findings from all iterations into a coherent whole</li> </ol>"},{"location":"lab-3-reflection/#lab-overview","title":"Lab Overview","text":"<p>In this lab, you'll:</p> <ol> <li>Build upon the web search capabilities from Lab 2</li> <li>Implement knowledge gap analysis with AI reasoning</li> <li>Create an iterative research system that conducts multiple search cycles</li> <li>Generate comprehensive research reports combining multiple iterations</li> <li>See real-time streaming of the AI's thinking throughout the entire process</li> </ol>"},{"location":"lab-3-reflection/#the-iterative-research-process","title":"The Iterative Research Process","text":"<p>The complete iterative research process includes:</p> <ol> <li>Initial query generation and web search (from Lab 2)</li> <li>Knowledge gap identification after initial research</li> <li>Follow-up search cycles based on identified gaps</li> <li>Synthesis of all findings into a comprehensive report</li> </ol>"},{"location":"lab-3-reflection/#the-code","title":"The Code","text":"<p>The Python application in <code>lab3_reflection.py</code> extends our Lab 2 implementation with knowledge gap identification and iterative research:</p> <pre><code>import os\nimport json\nimport time\nimport dotenv\nfrom typing import Dict, List, Any, Tuple\nfrom langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom tavily import TavilyClient\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.prompt import Prompt\nfrom rich.progress import Progress, SpinnerColumn, TextColumn\nfrom rich.live import Live\n\n# ... abbreviated for clarity ...\n</code></pre>"},{"location":"lab-3-reflection/#key-components","title":"Key Components","text":""},{"location":"lab-3-reflection/#knowledge-gap-identification","title":"Knowledge Gap Identification","text":"<p>After the initial research cycle, the system analyzes what information is missing:</p> <pre><code>def identify_knowledge_gaps(research_topic, current_summary):\n    \"\"\"Identify knowledge gaps and generate a follow-up query.\"\"\"\n    console.print(\"\\n[bold blue]Identifying knowledge gaps...[/]\")\n\n    messages = [\n        SystemMessage(content=REFLECTION_PROMPT),\n        HumanMessage(content=f\"Research Topic: {research_topic}\\n\\nCurrent Summary:\\n{current_summary}\")\n    ]\n\n    # Stream the model's thinking process for knowledge gap identification\n    console.print(\"\\n[bold]Knowledge Gap Analysis Process:[/]\\n\")\n    response_stream = model.stream(messages)\n    thoughts, json_str = stream_thinking_and_answer(response_stream, \"\ud83d\udd0d Reflection Thinking\")\n\n    # Try to parse the JSON response\n    try:\n        reflection = json.loads(json_str)\n        knowledge_gap = reflection.get(\"knowledge_gap\", \"No specific knowledge gap identified.\")\n        follow_up_query = reflection.get(\"follow_up_query\", f\"More information about {research_topic}\")\n    except json.JSONDecodeError:\n        # Fallback if JSON parsing fails\n        knowledge_gap = \"Unable to parse the identified knowledge gap.\"\n        follow_up_query = f\"More information about {research_topic}\"\n\n    display_panel(\n        f\"**Knowledge Gap**: {knowledge_gap}\\n\\n**Follow-up Query**: {follow_up_query}\",\n        \"\ud83d\udd0d Knowledge Gap Analysis\",\n        \"yellow\"\n    )\n\n    return knowledge_gap, follow_up_query\n</code></pre> <p>This function: - Analyzes the current research summary to identify knowledge gaps - Generates a specific follow-up query to address the most important gap - Returns both the knowledge gap description and the follow-up query - Streams the model's thinking process in real-time</p>"},{"location":"lab-3-reflection/#multi-iteration-research","title":"Multi-Iteration Research","text":"<p>The <code>conduct_research</code> function now performs multiple research iterations:</p> <pre><code>def conduct_research(research_topic, max_iterations=2):\n    \"\"\"Conduct multi-step research on a topic.\"\"\"\n    console.print(f\"[bold]Starting research on: [green]{research_topic}[/green][/]\\n\")\n\n    all_summaries = []\n\n    for iteration in range(1, max_iterations + 1):\n        console.print(f\"\\n[bold]===== Research Iteration {iteration} =====[/]\\n\")\n\n        # Generate search query (use the research topic for first iteration)\n        if iteration == 1:\n            query = generate_search_query(research_topic)\n        else:\n            # For subsequent iterations, use the follow-up query from reflection\n            _, query = identify_knowledge_gaps(research_topic, all_summaries[-1])\n\n        # Perform web search\n        search_results = perform_web_search(query)\n\n        # Summarize search results\n        summary = summarize_search_results(research_topic, search_results)\n        all_summaries.append(summary)\n\n    # Compile final research report from all summaries\n    console.print(\"\\n[bold]===== Final Research Report =====[/]\\n\")\n\n    final_report = f\"# Research Report: {research_topic}\\n\\n\"\n    for i, summary in enumerate(all_summaries, 1):\n        final_report += f\"## Research Cycle {i}\\n\\n{summary}\\n\\n\"\n\n    display_panel(final_report, \"\ud83d\udcca Complete Research Report\", \"purple\")\n\n    return final_report\n</code></pre> <p>This function: - Performs multiple research iterations (default is 2) - Uses the initial topic for the first search - Uses knowledge gap analysis to guide subsequent searches - Compiles all findings into a comprehensive final report</p>"},{"location":"lab-3-reflection/#research-report-compilation","title":"Research Report Compilation","text":"<p>The final report combines findings from all research iterations:</p> <pre><code># Compile final research report from all summaries\nconsole.print(\"\\n[bold]===== Final Research Report =====[/]\\n\")\n\nfinal_report = f\"# Research Report: {research_topic}\\n\\n\"\nfor i, summary in enumerate(all_summaries, 1):\n    final_report += f\"## Research Cycle {i}\\n\\n{summary}\\n\\n\"\n\ndisplay_panel(final_report, \"\ud83d\udcca Complete Research Report\", \"purple\")\n</code></pre> <p>This creates a well-structured report with sections for each research cycle.</p>"},{"location":"lab-3-reflection/#running-the-application","title":"Running the Application","text":"<p>To run the application:</p> <ol> <li>Ensure you have the required packages installed:</li> </ol> <pre><code>pip install python-dotenv langchain-azure-ai tavily-python rich\n</code></pre> <ol> <li>Make sure your <code>.env</code> file includes both Azure OpenAI and Tavily API keys:</li> </ol> <pre><code>AZURE_AI_ENDPOINT=your_azure_openai_endpoint\nAZURE_API_KEY=your_azure_openai_key\nTAVILY_API_KEY=your_tavily_api_key\n</code></pre> <ol> <li>Run the script:</li> </ol> <pre><code>python lab3_reflection.py\n</code></pre> <ol> <li>Enter a research topic and observe the multi-cycle research process.</li> </ol>"},{"location":"lab-3-reflection/#example-usage","title":"Example Usage","text":"<p>When you run the application and enter a research topic like \"quantum computing applications in medicine\", you'll see:</p> <ol> <li>First Research Cycle:</li> <li>Generation of an initial search query</li> <li>Web search results</li> <li> <p>Summary of initial findings</p> </li> <li> <p>Knowledge Gap Analysis:</p> </li> <li>Identification of missing information</li> <li> <p>Generation of a follow-up query</p> </li> <li> <p>Second Research Cycle:</p> </li> <li>Web search using the follow-up query</li> <li> <p>Summary of additional findings</p> </li> <li> <p>Final Research Report:</p> </li> <li>Comprehensive report combining all research cycles</li> </ol>"},{"location":"lab-3-reflection/#benefits-of-iterative-research","title":"Benefits of Iterative Research","text":"<p>This approach offers several advantages:</p> <ol> <li>Thoroughness: Multiple research cycles produce more comprehensive results</li> <li>Targeted Follow-up: Each cycle focuses on what's still unknown</li> <li>Progressive Refinement: Later cycles build on knowledge from earlier ones</li> <li>Better Coverage: Different search queries capture different aspects of the topic</li> <li>Self-Awareness: The system acknowledges what it doesn't know</li> </ol>"},{"location":"lab-3-reflection/#lab-challenges","title":"Lab Challenges","text":"<p>Try these challenges to extend your learning:</p> <ol> <li>Increase Iterations: Modify the code to perform 3 or more research cycles</li> <li>Topic Segmentation: Modify the system to explore different subtopics in parallel</li> <li>User Guidance: Add user input between iterations to guide the research direction</li> <li>Sentiment Analysis: Add analysis of different perspectives on controversial topics</li> <li>Citation Improvement: Create a more formal citation system for sources</li> </ol>"},{"location":"lab-3-reflection/#key-takeaways","title":"Key Takeaways","text":"<p>From this lab, you should understand:</p> <ul> <li>How to implement knowledge gap identification</li> <li>Techniques for creating targeted follow-up queries</li> <li>Methods for conducting multi-cycle research</li> <li>The value of iterative approaches in comprehensive research</li> </ul>"},{"location":"lab-3-reflection/#next-steps","title":"Next Steps","text":"<p>Ready to incorporate this research system into a full production application? Move on to Lab 4: Launching Your Researcher.</p>"},{"location":"lab-4-launch-researcher/","title":"Lab 4: Deploying Your Research Assistant","text":"<p>In this lab, you'll transform your terminal-based research assistant into a professional web application using FastAPI and WebSockets. This web interface provides a more user-friendly experience with real-time research updates and a polished UI.</p>"},{"location":"lab-4-launch-researcher/#understanding-web-application-deployment","title":"Understanding Web Application Deployment","text":"<p>Moving from a command-line tool to a web application offers several advantages:</p> <ol> <li>User Accessibility: Anyone can use the application through a web browser</li> <li>Real-time Updates: WebSockets enable live streaming of research progress</li> <li>Professional Presentation: A well-designed UI enhances the research experience</li> <li>Scalability: The application can be deployed to cloud services for broader access</li> </ol>"},{"location":"lab-4-launch-researcher/#lab-overview","title":"Lab Overview","text":"<p>In this lab, you'll:</p> <ol> <li>Learn about the FastAPI web framework</li> <li>Set up a WebSocket connection for real-time streaming</li> <li>Create a research workflow using a state graph</li> <li>Deploy a responsive web interface</li> <li>See all previous lab techniques integrated into a production-ready application</li> </ol>"},{"location":"lab-4-launch-researcher/#architecture-overview","title":"Architecture Overview","text":"<p>The web application uses a modern architecture:</p> <ol> <li>Backend: FastAPI Python server with WebSocket support</li> <li>Frontend: HTML/CSS/JavaScript with Tailwind CSS for styling</li> <li>State Management: LangGraph for structured AI workflow orchestration</li> <li>Data Flow: Real-time bidirectional communication via WebSockets</li> </ol> <p></p>"},{"location":"lab-4-launch-researcher/#key-components","title":"Key Components","text":""},{"location":"lab-4-launch-researcher/#fastapi-application","title":"FastAPI Application","text":"<p>The main application in <code>app/main.py</code> serves as the backend server:</p> <pre><code>from fastapi import FastAPI, WebSocket, WebSocketDisconnect\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\nfrom langgraph.graph import StateGraph, START, END\n# ... other imports ...\n\napp = FastAPI(title=\"Azure Deep Research\")\n\n# Mount static files\napp.mount(\"/static\", StaticFiles(directory=\"app/static\"), name=\"static\")\n\n# Set up templates\ntemplates = Jinja2Templates(directory=\"app/templates\")\n</code></pre>"},{"location":"lab-4-launch-researcher/#research-graph-with-langgraph","title":"Research Graph with LangGraph","text":"<p>The application uses LangGraph to create a structured research workflow:</p> <pre><code>def setup_graph():\n    # Add nodes and edges\n    builder = StateGraph(SummaryState, input=SummaryStateInput, output=SummaryStateOutput)\n    builder.add_node(\"generate_query\", generate_query)\n    builder.add_node(\"web_research\", web_research)\n    builder.add_node(\"summarize_sources\", summarize_sources)\n    builder.add_node(\"reflect_on_summary\", reflect_on_summary)\n    builder.add_node(\"finalize_summary\", finalize_summary)\n\n    # Add edges\n    builder.add_edge(START, \"generate_query\")\n    builder.add_edge(\"generate_query\", \"web_research\")\n    builder.add_edge(\"web_research\", \"summarize_sources\")\n    builder.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n    builder.add_conditional_edges(\"reflect_on_summary\", route_research)\n    builder.add_edge(\"finalize_summary\", END)\n\n    return builder.compile()\n</code></pre> <p>This creates a research graph with: 1. Query generation 2. Web research retrieval 3. Information summarization 4. Knowledge gap reflection 5. Multiple research cycles 6. Final report generation</p>"},{"location":"lab-4-launch-researcher/#websocket-communication","title":"WebSocket Communication","text":"<p>Real-time updates are provided through WebSockets:</p> <pre><code>@app.websocket(\"/ws/{client_id}\")\nasync def websocket_endpoint(websocket: WebSocket, client_id: str):\n    await websocket.accept()\n    manager.connect(websocket, client_id)\n    try:\n        # Set up the graph\n        graph = setup_graph()\n\n        while True:\n            data = await websocket.receive_text()\n            data_json = json.loads(data)\n\n            if data_json.get(\"type\") == \"research\":\n                # ... start research process ...\n\n                async def stream_graph_updates():\n                    # ... stream updates to client ...\n\n                # Run graph execution in the background\n                asyncio.create_task(stream_graph_updates())\n\n    except WebSocketDisconnect:\n        manager.disconnect(client_id)\n</code></pre>"},{"location":"lab-4-launch-researcher/#interactive-web-interface","title":"Interactive Web Interface","text":"<p>The web interface in <code>app/templates/index.html</code> provides a clean, responsive UI:</p> <ul> <li>Research topic input</li> <li>Real-time progress indicators</li> <li>Live streaming of research steps</li> <li>Formatted research report display</li> <li>\"AI Thinking\" modal to show reasoning process</li> </ul>"},{"location":"lab-4-launch-researcher/#running-the-application","title":"Running the Application","text":"<p>To launch the web application:</p> <ol> <li>Install the required dependencies:</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre> <ol> <li>Start the FastAPI server:</li> </ol> <pre><code>uvicorn app.main:app --reload\n</code></pre> <ol> <li>Open your browser and navigate to:</li> </ol> <pre><code>http://localhost:8000\n</code></pre>"},{"location":"lab-4-launch-researcher/#using-the-web-interface","title":"Using the Web Interface","text":"<p>The web application features a clean, intuitive interface:</p> <ol> <li>Research Input: Enter a research topic in the input field and click \"Research\"</li> <li>Progress Tracking: Watch as the system progresses through each research step</li> <li>Live Updates: See real-time updates as the research is conducted</li> <li>Thinking Process: Click the thought bubble icon to view the AI's reasoning process</li> <li>Final Report: View the comprehensive research report with citations</li> </ol>"},{"location":"lab-4-launch-researcher/#behind-the-scenes","title":"Behind the Scenes","text":"<p>When a user submits a research topic, the application:</p> <ol> <li>Initializes a WebSocket connection for real-time communication</li> <li>Creates a research graph using LangGraph</li> <li>Executes the research workflow in a structured way:</li> <li>Generates an effective search query with visible thinking</li> <li>Performs web searches using the Tavily API</li> <li>Synthesizes information from search results</li> <li>Identifies knowledge gaps and creates follow-up queries</li> <li>Conducts multiple research cycles (up to 3 by default)</li> <li>Compiles a final research report with images and sources</li> <li>Streams progress updates to the client in real-time</li> <li>Displays the final research report with proper formatting</li> </ol>"},{"location":"lab-4-launch-researcher/#deployment-options","title":"Deployment Options","text":"<p>After testing locally, you can deploy the application to various platforms:</p>"},{"location":"lab-4-launch-researcher/#azure-app-service","title":"Azure App Service","text":"<ol> <li>Create an Azure App Service with Python support</li> <li>Set up your environment variables in the App Service configuration</li> <li>Deploy your code using Azure DevOps, GitHub Actions, or direct deployment</li> </ol>"},{"location":"lab-4-launch-researcher/#docker-deployment","title":"Docker Deployment","text":"<ol> <li>Create a Dockerfile in your project root:</li> </ol> <pre><code>FROM python:3.10\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <ol> <li>Build and run the Docker container:</li> </ol> <pre><code>docker build -t azure-deep-research .\ndocker run -p 8000:8000 -d azure-deep-research\n</code></pre>"},{"location":"lab-4-launch-researcher/#enhancing-your-application","title":"Enhancing Your Application","text":"<p>Consider these enhancements for your research assistant:</p> <ol> <li>User Authentication: Add user accounts and save research history</li> <li>Database Integration: Store research reports for later reference</li> <li>Research Export: Add options to export as PDF or other formats</li> <li>Custom Research Settings: Allow users to adjust research depth and sources</li> <li>Document Upload: Enable research based on uploaded documents</li> </ol>"},{"location":"lab-4-launch-researcher/#lab-challenges","title":"Lab Challenges","text":"<p>Try these challenges to extend your learning:</p> <ol> <li>Add Visualization: Integrate data visualization for numerical research topics</li> <li>Implement Caching: Add result caching to improve performance</li> <li>Multi-Language Support: Add translation capabilities for multiple languages</li> <li>Citation Management: Implement formal academic citation formats</li> <li>Image Analysis: Add capabilities to analyze images found during research</li> </ol>"},{"location":"lab-4-launch-researcher/#key-takeaways","title":"Key Takeaways","text":"<p>From this lab, you should understand:</p> <ul> <li>How to deploy an AI research assistant as a web application</li> <li>Using WebSockets for real-time communication</li> <li>Implementing a structured workflow with LangGraph</li> <li>Creating an interactive user interface for research</li> <li>Integrating all previous lab techniques into a production application</li> </ul>"},{"location":"lab-4-launch-researcher/#congratulations","title":"Congratulations!","text":"<p>You've successfully built and deployed a sophisticated AI research assistant using Azure OpenAI, LangGraph, and FastAPI. This application demonstrates modern AI techniques including:</p> <ul> <li>Transparent thinking and reasoning</li> <li>Web search integration</li> <li>Knowledge gap identification</li> <li>Iterative research cycles</li> <li>Real-time progress streaming</li> </ul> <p>Your application now provides a powerful research tool that can help users explore any topic with the assistance of advanced AI capabilities.</p>"}]}