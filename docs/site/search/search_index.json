{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LAB331: Deep Research with LangChain and DeepSeek R1","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Welcome to Lab 331! In this hands-on workshop, you'll learn how Reasoning Models, like DeepSeek R1 work and how to use them for deep research. </p> <p></p>"},{"location":"#what-youll-build","title":"What You'll Build","text":"<p>We'll walk through how to build a research assistant that can conduct comprehensive web research, analyze and synthesize information, and present it's findings.</p>"},{"location":"#the-complete-iterative-deep-research-process-includes","title":"The complete iterative deep research process includes:","text":"<ol> <li>Query Generation: Query generation based on the users research topic input </li> <li>Web Search: Searching the web based on the generated query</li> <li>Summarization: Summarization of the web search results into a report</li> <li>Knowledge Gap Identification: Reflection on the summary and identification of specific knowledge gaps to fill</li> <li>Follow-up search cycles: Iterative search and reflection cycles based on identified gaps</li> <li>Final Report: Synthesis of all findings into a comprehensive report</li> </ol>"},{"location":"#what-youll-learn","title":"What You'll Learn","text":"<p>This workshop has been built to teach you foundational concepts for using reasoning models. To view the full application code see the Deep Research Azure Sample. For a more in depth understanding of how reasoning models work read this article. </p>"},{"location":"#by-the-end-of-this-workshop-youll-have-learnt","title":"By the end of this workshop, you'll have learnt:","text":"<ul> <li>What a reasoning model is and how to use DeepSeek R1</li> <li>How to use reasoning models with tools like Tavily web search for optimum search results</li> <li>What LangGraph is and how to implement reflection style archictecture with it</li> <li>How to use LangGraph to perform iterative research cycles to build comprehensive knowledge</li> <li>How to deploy the final application</li> </ul>"},{"location":"#workshop-structure","title":"Workshop Structure","text":"<p>The workshop is organized into four labs:</p> <ol> <li>Introduction to Reasoning Models</li> <li>Web Research Integration</li> <li>Research Reflection</li> <li>Launching Your Researcher</li> </ol>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To begin the workshop, proceed to the Getting Started section to set up your environment and install the necessary dependencies.</p>"},{"location":"getting-started/","title":"Getting Started","text":"Microsoft Build AttendeesSelf Paced Attendees <p>The instructions on this page assume you are attending Microsoft Build 2025 and have access to a pre-configured lab environment. This environment provides an Azure subscription with all the tools and resources needed to complete the workshop. </p> <p>If you are following this workshop outside of a Skillable environment follow the instructions here to setup and then continue to Lab 1. </p>"},{"location":"getting-started/#introduction","title":"Introduction","text":"<p>This workshop is designed to teach you how to use Reasoning Models, like DeepSeek R1 and utilize tools and Reflection style architecture with LangChain to do deep research. It consists of multiple labs, each highlighting a specific feature of the process of building a deep researcher. The labs are meant to be completed in order, as each one builds on the knowledge and work from the previous lab.</p>"},{"location":"getting-started/#authenticate-with-azure","title":"Authenticate with Azure","text":"<p>You need to authenticate with Azure to access DeepSeek R1. Follow these steps:</p> <ol> <li> <p>Open a terminal window. The terminal app is pinned to the Windows taskbar.</p> <p></p> </li> <li> <p>Run the following command to authenticate with Azure:</p> <pre><code>az login\n</code></pre> <p>Note</p> <p>You'll be prompted to open a browser link and log in to your Azure account.</p> <ol> <li> <p>A browser window will open automatically, select Work or school account and click Next.</p> </li> <li> <p>Use the Username and Password found in the top section of the Resources tab in the lab environment.</p> </li> <li> <p>Select OK, then Done.</p> </li> </ol> </li> <li> <p>Stay in the terminal window for the next step.</p> </li> </ol>"},{"location":"getting-started/#open-the-workshop-and-setup-your-tavily-account","title":"Open the Workshop and setup your Tavily account","text":"<p>Follow these steps to open the workshop in Visual Studio Code and set up your Tavily account for web search:</p> <ol> <li> <p>From the terminal window, execute the following commands to clone the workshop repository, navigate to the relevant folder, set up a virtual environment, activate it, and install the required packages:</p> <pre><code>git clone https://github.com/microsoft/BUILD25-LAB331.git `\n; cd BUILD25-LAB331 `\n; python -m venv src/.venv `\n; src\\.venv\\Scripts\\activate `\n; pip install -r src/requirements.txt `\n; cd src `\n;\n</code></pre> <p>Warning</p> <p>This command will take a few minutes to complete. While you wait, navigate to the Tavily home page that should already be opened as a tab in your browser. </p> </li> <li> <p>We will be using Tavily to give our deep researcher access to the internet. Once on the Tavily page, click the sign up button and create an account. </p> <p>Note</p> <p>You will need to use either your personal email address or your Github account to sign up since email requires verification. </p> <p>Click the signup button and complete the sign up process </p> <p></p> <p>Once sign up is complete you should see a page with an API Key that looks like this. You will use this key later, so minimize the page for now and return to the terminal. </p> <p></p> </li> <li> <p>From the terminal window, run the following command to open the project in VS Code (note there is a period after the word code. Do not just type in 'code', the period is important.):</p> <pre><code>code .\n</code></pre> <p>When the project opens in VS Code, two notifications appear in the bottom right corner. Click \u2716 to close both notifications.</p> </li> </ol>"},{"location":"getting-started/#configure-the-workshop","title":"Configure the Workshop","text":""},{"location":"getting-started/#create-the-env-file","title":"Create the .env file","text":"<ol> <li> <p>Open a new terminal in VSCode. </p> </li> <li> <p>To create a <code>.env</code> file with the variables needed for this workshop click on the <code>instructions</code> tab in your Skillable lab manual. Click on the command under Lab Guide and patse it in the terminal. Press enter to run the command and follow the instructions.</p> <p></p> </li> <li> <p>Check that your .env file has succesfully been created and contains some variables. If not, raise your hand and ask a proctor for help.</p> </li> <li>Navigate back to the Tavily API page you should have open in your browser. Copy the API Key and paste it in the .env file as the <code>TAVILY_API_KEY</code> value.</li> </ol> <p>You can now begin with Lab 1! </p>"},{"location":"getting-started/#pro-tips","title":"Pro Tips","text":"<p>Tips</p> <ol> <li>The Burger Menu in the right-hand panel of the lab environment offers additional features, including the Split Window View and the option to end the lab. The Split Window View allows you to maximize the lab environment to full screen, optimizing screen space. The lab's Instructions and Resources panel will open in a separate window.</li> <li>If the lab instructions are slow to scroll in the lab environment, try copying the instructions\u2019 URL and opening it in your computer\u2019s local browser for a smoother experience.</li> <li>If you have trouble viewing an image, simply click the image to enlarge it.</li> </ol>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Once your environment is set up, proceed to Lab 1: Introduction to Reasoning Models to begin building your research assistant.</p>"},{"location":"lab-1-introduction-to-reasoning-models/","title":"Lab 1: Introduction to Reasoning Models","text":""},{"location":"lab-1-introduction-to-reasoning-models/#what-is-a-reasoning-model","title":"What is a Reasoning Model?","text":"<p>Reasoning models are LLMs trained with reinforcement learning to perform reasoning. These models think before they answer, producing a long internal chain of thought before responding to the user.</p> <p>When combined with tools to access the web, reasoning models are particularly good at research. Their chain\u2011of\u2011thought training and reward signals make them better at spotting gaps, cross\u2011checking sources, and iterating on hypotheses. </p>"},{"location":"lab-1-introduction-to-reasoning-models/#some-popular-reasoning-models-include","title":"Some popular reasoning models include:","text":"<ul> <li>DeepSeek R1, </li> <li>o3 and o1</li> <li>Phi-4-reasoning.</li> </ul>"},{"location":"lab-1-introduction-to-reasoning-models/#getting-started-with-deepseek-r1","title":"Getting started with DeepSeek R1","text":"<p>To access DeepSeek R1 we will be using langchain-azure-ai, the official Python package that contains most of Langchain's Azure integrations. This package leverages the Azure AI Inference SDK to give us access to all the models available in Azure AI Foundry using Langchain. </p>"},{"location":"lab-1-introduction-to-reasoning-models/#lab-exercise","title":"Lab Exercise","text":"<ol> <li> <p>Open the file <code>lab1a_reasoning.py</code> and examine the code in this file.</p> </li> <li> <p>In the VS Code terminal run the following command and enter a research topic. For example 'What's the best coffee in Seattle?'\u2615:</p> <pre><code>python lab1a_reasoning.py\n</code></pre> </li> </ol> <p>Note</p> <p>\ud83e\udde0\u2728 Thinking... What do you notice about the answer DeepSeek R1 returns vs what a chat model would typically output? </p> <p>Reasoning models 'think' and show you how they arrived at the final answer!</p> <p>Type in exit to leave the program and continue with the next section. </p>"},{"location":"lab-1-introduction-to-reasoning-models/#seperating-thinking-from-the-final-answer","title":"Seperating Thinking from the Final Answer","text":"<p>The output from the model in the previous step contains the models thinking. This output might be helpful for developers but might not always be useful when building an application where users only expect the final output. </p> <p>Tip</p> <p>Many reasoning models put their thought process in thinking tags that look like this  <code>&lt;think&gt; &lt;/think&gt;</code>. </p> <p>In order to seperate the models thinking from it's final answer we can create helper function in Python to seperate the thinking from the final output. The function would look like this:</p> <pre><code>def seperate_thinking_from_final_output(text: str):\n    \"\"\"\n    Extract the content between &lt;think&gt; and &lt;/think&gt; tags and remove them from the text.\n    \"\"\"\n    thoughts = \"\"\n    while \"&lt;think&gt;\" in text and \"&lt;/think&gt;\" in text:\n        start = text.find(\"&lt;think&gt;\")\n        end = text.find(\"&lt;/think&gt;\")\n        # Extract the content between tags (excluding the tags themselves)\n        thoughts += text[start + len(\"&lt;think&gt;\"):end].strip() + \"\\n\\n\"\n        # Remove the tags and their content from the original text\n        text = text[:start] + text[end + len(\"&lt;/think&gt;\"):]\n    return thoughts.strip(), text.strip()\n</code></pre>"},{"location":"lab-1-introduction-to-reasoning-models/#lab-exercise_1","title":"Lab Exercise","text":"<ol> <li> <p>Open the <code>stream_llm_response.py</code> file and examine the code in this file. </p> <p>It contains a slightly updated version of this helper function in the <code>stream_thinking_and_answer</code> function. This helper function will be imported in all our python files going forward. It also contains some code that uses the Python package rich for prettier display in the terminal. </p> </li> <li> <p>To test that this code works we can run the <code>lab1b_reasoning.py</code> script which imports the helper function. Run the following command in the terminal to do so:</p> <pre><code>python lab1b_reasoning.py\n</code></pre> </li> </ol>"},{"location":"lab-1-introduction-to-reasoning-models/#updating-the-system-prompt","title":"Updating the System Prompt","text":"<p>The final output is returned as bullet points. This format can be specified in the models system prompt that tells the LLM how to behave. You do not need to add a system prompt but these can be useful for improving the format and contextual relevance of the models final response.</p> <p>The current system prompt in <code>lab1b_reasoning.py</code> is: </p> <pre><code>SYSTEM_PROMPT = \"\"\"\nYou are a research assistant that thinks carefully about questions before answering.\n\nWhen you receive a research question, first think about the problem step-by-step.\n\nAfter thinking, provide your final answer in bullet points.\nMake sure to include all the important details in your answer.\n</code></pre>"},{"location":"lab-1-introduction-to-reasoning-models/#lab-exercise_2","title":"Lab Exercise","text":"<ol> <li> <p>Update the system prompt in <code>lab1b_reasoning.py</code> to change the final output format. For example ask the model to return the answer as a table or in a Q&amp;A format. </p> </li> <li> <p>Rerun the following command in the terminal to test your updates:</p> <pre><code>python lab1b_reasoning.py\n</code></pre> </li> </ol>"},{"location":"lab-1-introduction-to-reasoning-models/#next-steps","title":"Next Steps","text":"<p>Congratulations, you should now feel comfortable using reasoning models!  You are now ready to move on to Lab 2: Web Research Integration.</p>"},{"location":"lab-2-web-research/","title":"Lab 2: Web Research Integration","text":""},{"location":"lab-2-web-research/#why-should-we-connect-llms-to-the-web","title":"Why Should We Connect LLMs To The Web?","text":"<p>So far we have been using DeepSeek R1 to return an answer to our research questions. While LLMs have extensive knowledge, they have two major limitations:</p> <ol> <li>Training Data Cutoff: Models only have knowledge up to their training cutoff date</li> <li>Knowledge Limitations: No model knows everything, especially about niche or emerging topics</li> </ol> <p>By connecting LLMs to web search capabilities, you can:</p> <ul> <li>Obtain current information not available during model training</li> <li>Get authoritative information from reliable sources</li> <li>Research specialized topics where the model's knowledge may be limited</li> <li>Find specific data points, statistics, and references</li> </ul>"},{"location":"lab-2-web-research/#the-web-research-process","title":"The Web Research Process","text":"<p>To get the best web research results possible we will create a python script that involves three key components:</p> <ol> <li>Query Generation: Creating effective search queries based on the research topic</li> <li>Web Search: Retrieving relevant information from external sources</li> <li>Summarization: Integrating the retrieved information into a cohesive summary</li> </ol> <p></p>"},{"location":"lab-2-web-research/#query-generation","title":"Query Generation","text":"<p>We will begin by using DeepSeek R1 to generate an optimal search query based on the users research topic.  As we saw earlier the system prompt lets the model know how to respond. For the query generator we want the model to return  the optimizes search query and a brief explanation of why this query is relevant. </p> <p>Note</p> <p>This system prompt and others can be found in the <code>prompts.py</code> file. </p> <p>The system prompt for the query writer is as follows:</p> <pre><code>query_writer_instructions=\"\"\"Your goal is to generate a targeted web search query.\n\n&lt;CONTEXT&gt;\nCurrent date: {current_date}\nPlease ensure your queries account for the most current information available as of this date.\n&lt;/CONTEXT&gt;\n\n&lt;TOPIC&gt;\n{research_topic}\n&lt;/TOPIC&gt;\n\n&lt;FORMAT&gt;\nFormat your response as a JSON object with ALL three of these exact keys:\n   - \"query\": The actual search query string\n   - \"rationale\": Brief explanation of why this query is relevant\n&lt;/FORMAT&gt;\n\n&lt;EXAMPLE&gt;\nExample output:\n{{\n    \"query\": \"machine learning transformer architecture explained\",\n    \"rationale\": \"Understanding the fundamental structure of transformer models\"\n}}\n&lt;/EXAMPLE&gt;\n\nProvide your response in JSON format. Do not include any tags or backticks. Only return\nJson like in the example:\"\"\"\n</code></pre>"},{"location":"lab-2-web-research/#web-search","title":"Web Search","text":"<p>The generated query is then used to perform a web search using the Tavily API.  This is the code required:</p> <pre><code>def perform_web_search(query):\n    \"\"\"Perform a web search using the Tavily API.\"\"\"\n\n    search_results = tavily_client.search(query)\n\n    for i, result in enumerate(search_results[\"results\"]):\n        print(f\"**Result {i + 1}**\")\n        print(f\"**Title**: {result['title']}\")\n        print(f\"**Snippet**: {result['content']}\")\n        print(f\"**URL**: {result['url']}\\n\")\n\n    return search_results\n</code></pre> <p>Tavily retrieves information from the web about the topic and displays snippets of the results.</p> <p>Tip</p> <p>Tavily offers several options to alter the quality and quantity of the search_results.  To specify the number of search results use the <code>max_results</code> parameter.  To determine the depth of the search set the <code>search_depth</code> parameter to <code>basic</code> or <code>advanced</code>.  Advanced returns higher quality results but takes longer. </p>"},{"location":"lab-2-web-research/#lab-excercise","title":"Lab Excercise","text":"<ol> <li> <p>Examine the code in <code>lab2a_web_research.py</code>.</p> </li> <li> <p>Run the following command in the terminal to try out web search:</p> <pre><code>python lab2a_web_research.py\n</code></pre> </li> <li> <p>Update the code to test out returning more than one result and try the advanced search!</p> </li> </ol>"},{"location":"lab-2-web-research/#next-steps","title":"Next Steps","text":"<p>You have now learnt how to use a reasoning model with a search tool. The next step is to summarize the web results into a cohesive summary.  DeepSeek can be used to create the summary and then reflect on it so gaps can be identified and filled. To learn how this is done using LangGraph, move on to Lab 3: Research Reflection.</p>"},{"location":"lab-3-reflection/","title":"Lab 3: Research Reflection","text":""},{"location":"lab-3-reflection/#understanding-research-reflection","title":"Understanding Research Reflection","text":"<p>Even with web search capabilities, a single research cycle often leaves important questions unanswered. Real research is iterative - findings from initial searches reveal what else we need to know.</p> <p>Research reflection involves:</p> <ol> <li>Knowledge Gap Identification: Analyzing current information to find what's missing</li> <li>Follow-up Query Generation: Creating targeted follow-up questions to fill these gaps</li> <li>Multiple Research Cycles: Conducting iterative research to build comprehensive knowledge</li> <li>Progressive Synthesis: Combining findings from all iterations into a coherent whole</li> </ol> <p>The complete iterative 'Deep Research' process looks like this:</p> <p></p>"},{"location":"lab-3-reflection/#when-to-use-an-ai-framework","title":"When To Use An AI Framework","text":"<p>This process will give us the high quality results but veers away from the linear flow of the scripts we saw in the previous labs. As AI workflows become more complex, developers need to write code that takes into account things like states, conditional branching, tool use and more. To simplify this process it is often useful to use an AI framework. </p> <p>LangGraph is a Python framework that lets you build stateful, multi-step reasoning workflows using large language models by representing them as graphs. It\u2019s built on top of LangChain and designed for more complex use cases.</p>"},{"location":"lab-3-reflection/#using-langgraph-for-the-iterative-research-process","title":"Using LangGraph For The Iterative Research Process","text":""},{"location":"lab-3-reflection/#states-in-langgraph","title":"States in LangGraph","text":"<p>One of the things to note about this process is that we have to keep track of the state of the running summary and web results so we can update them with each iteration. LangGraph allows us to do this by creating an overall <code>State</code> class with different variables that can be updated and passed between steps.  For this project we create a <code>SummaryState</code> that looks like this:</p> <pre><code>class SummaryState:\n    research_topic: str = field(default=None) # Report topic     \n    search_query: str = field(default=None) # Search query\n    rationale: str = field(default=None) # rationale for the search query\n    web_research_results: Annotated[list, operator.add] = field(default_factory=list) \n    sources_gathered: Annotated[list, operator.add] = field(default_factory=list) \n    research_loop_count: int = field(default=0) # Research loop count\n    running_summary: str = field(default=None) # Final report\n    knowledge_gap: str = field(default=None) # Knowledge gap\n</code></pre> <p>This state is what is passed between the different functions and allows us at anytime to check any variable. </p> <p>Tip</p> <p>\ud83e\udde0 Key Concepts in LangGraph:</p> <p>Nodes = individual steps that can update the state in some way (e.g. get web research results, retrieve docs, update memory)</p> <p>Edges = the transitions between those steps, which can depend on model outputs</p> <p>State = shared memory or variables passed between steps</p> <p>Loops &amp; Branching (Conditional Edges) = supports revisiting steps or changing paths based on conditions</p>"},{"location":"lab-3-reflection/#nodes-and-edges-in-langgraph","title":"Nodes And Edges in LangGraph","text":"<p>In order for us to carry out iterative research we need a way to be able to know when to keep researching and when to return the final report. We can create a function that contains some condition that decides which route to take. In LangGraph such a function is called a conditional edge. For our Deep Researcher we will set the simple condition of whether research has been done 3 times (remember 0 is included). The function looks like this:</p> <pre><code>def route_research(state: SummaryState):\n    if state.research_loop_count &lt;= 1:\n        return \"web_research\"\n    else:\n        return \"finalize_summary\" \n</code></pre> <p>If the <code>web_research</code> function is returned LangGraph will call that function, passing the follow_up_query to it. This query would have been generated by the <code>identify_knowledge_gaps</code> function which uses DeepSeek R1 to reflect on the current summary and to identify knowledge gaps to fill. This function like most of the ones we've seen so far can update the SummaryState and so is considered a Node. </p>"},{"location":"lab-3-reflection/#lab-excercise","title":"Lab Excercise","text":"<ol> <li>Examine the reflection_instructions in <code>prompts.py</code> and see how this is used to prompt the model to generate a thoughtful follow up query.</li> <li>Examine the code in <code>lab3a_reflection.py</code> to see a simplfied version of how a Deep Researcher graph would be built </li> <li> <p>Run the following command to visualize the graph using LangGraph's in built function:</p> <pre><code>python lab3a_reflection.py\n</code></pre> <p>you should see a mermaid diagram like this: </p> </li> </ol>"},{"location":"lab-3-reflection/#putting-it-all-together","title":"Putting it all together","text":""},{"location":"lab-3-reflection/#lab-excercise_1","title":"Lab Excercise","text":"<ol> <li> <p>To see the full researcher in action run the following command:</p> <pre><code>python lab3b_reflection.py\n</code></pre> </li> </ol>"},{"location":"lab-3-reflection/#next-steps","title":"Next Steps","text":"<p>We can now put everything we've learnt into practice by building a Deep Rearch application. Move on to Lab 4: Launching Your Researcher.</p>"},{"location":"lab-4-launch-researcher/","title":"Lab 4: Launching Your Research Assistant","text":"<p>In this lab, you'll transform your terminal-based research assistant into a professional web application!</p>"},{"location":"lab-4-launch-researcher/#application-overview","title":"Application Overview","text":"<p>The web application uses:</p> <ol> <li>Backend: FastAPI Python server with WebSocket support</li> <li>Frontend: HTML/CSS/JavaScript with Tailwind CSS for styling</li> </ol> <p>Your launched application should look like this when running your research: </p> <p></p>"},{"location":"lab-4-launch-researcher/#running-the-application","title":"Running the Application","text":"<p>To launch the web application:</p> <ol> <li>Install the required dependencies:</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre> <ol> <li>Start the FastAPI server:</li> </ol> <pre><code>uvicorn app.main:app --reload\n</code></pre> <ol> <li>Open your browser and navigate to:</li> </ol> <pre><code>http://localhost:8000\n</code></pre>"},{"location":"lab-4-launch-researcher/#using-the-web-interface","title":"Using the Web Interface","text":"<p>The web application features a clean, intuitive interface:</p> <ol> <li>Research Input: Enter a research topic in the input field and click \"Research\"</li> <li>Progress Tracking: Watch as the system progresses through each research step</li> <li>Live Updates: See real-time updates as the research is conducted</li> <li>Thinking Process: Click the thought bubble icon to view the AI's reasoning process</li> <li>Final Report: View the comprehensive research report with citations</li> </ol>"},{"location":"lab-4-launch-researcher/#congratulations","title":"Congratulations!","text":"<p>You've successfully built and deployed a Deep Researcher using DeepSeek R1, LangChain, and FastAPI!</p> <p>Checkout the Summary to see an overview of what you learnt and navigate to the Resources page for links to access this lab and more at home! </p>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#workshop-repository-and-documentation","title":"Workshop Repository and Documentation","text":"<p>The workshop repository on GitHub contains everything needed for the workshop. The repo includes the source code (src folder) for the sample application, the documentation (docs) built with MkDocs, and the Azure deployment resources (infra) for the workshop.</p> <ul> <li>Repository: microsoft/BUILD25-LAB331/tree/main</li> </ul> <p>This project is also avaialable as an Azure Sample. If you enjoyed this workshop please star the repo\u2b50</p> <ul> <li>Deep Research</li> </ul> <p>This workshop is based on the Open Deep Research repository from Langchain. Thank you to the Langchain team for their excellent OSS work! </p> <ul> <li>Langchain Open Deep Research</li> </ul>"},{"location":"resources/#other-resources","title":"Other resources","text":"<ul> <li>Azure AI Foundry </li> <li>LangGraph Documentation</li> <li>Tavily Python SDK</li> </ul>"},{"location":"resources/#thank-you","title":"Thank you","text":"<p>Thank you for participating in this workshop! If you have any suggestions for improvements or encountered any problems while running this workshop, please let us know via GitHub Issues.</p>"},{"location":"summary/","title":"Workshop Summary","text":"<p>Congratulations on completing the workshop! Let's recap what you've learned and built throughout this journey.</p>"},{"location":"summary/#in-this-workshop-you-built-a-deep-researcher-that-uses-deepseek-r1-to-complete-the-following-steps","title":"In this workshop you built a deep researcher that uses DeepSeek R1 to complete the following steps:","text":"<ol> <li>Query Generation: Query generation based on the users research topic input </li> <li>Web Search: Searching the web based on the generated query</li> <li>Summarization: Summarization of the web search results into a report</li> <li>Knowledge Gap Identification: Reflection on the summary and identification of specific knowledge gaps to fill</li> <li>Follow-up search cycles: Iterative search and reflection cycles based on identified gaps</li> <li>Final Report: Synthesis of all findings into a comprehensive report</li> </ol>"},{"location":"summary/#in-completing-the-workshop-you-learnt","title":"In completing the workshop you learnt:","text":"<ul> <li>What a reasoning model is and how to use DeepSeek R1</li> <li>How to use reasoning models with tools like Tavily web search for optimum search results</li> <li>What LangGraph is and how to implement reflection style archictecture with it</li> <li>How to use LangGraph to perform iterative research cycles to build comprehensive knowledge</li> <li>How to launch the final application</li> </ul> <p>By understanding the core components and patterns, you can extend this framework to solve a wide range of problems!</p> <p>Thank you for participating in this workshop. We hope you've gained valuable skills.</p>"},{"location":"includes/introduction-event/","title":"Introduction event","text":""},{"location":"includes/introduction-event/#microsoft-build-attendees","title":"Microsoft Build Attendees","text":"<p>The instructions on this page assume you are attending Microsoft Build 2025 and have access to a pre-configured lab environment. This environment provides an Azure subscription with all the tools and resources needed to complete the workshop.</p>"},{"location":"includes/introduction-event/#introduction","title":"Introduction","text":"<p>This workshop is designed to teach you how to use Reasoning Models, like DeepSeek R1 and utilize tools and Reflection style architecture with LangChain to do deep research. It consists of multiple labs, each highlighting a specific feature of the process of building a deep researcher. The labs are meant to be completed in order, as each one builds on the knowledge and work from the previous lab.</p>"},{"location":"includes/introduction-event/#authenticate-with-azure","title":"Authenticate with Azure","text":"<p>You need to authenticate with Azure so the agent app can access the Azure AI Agents Service and models. Follow these steps:</p> <ol> <li> <p>Open a terminal window. The terminal app is pinned to the Windows 11 taskbar.</p> <p></p> </li> <li> <p>Run the following command to authenticate with Azure:</p> <pre><code>az login\n</code></pre> <p>Note</p> <p>You'll be prompted to open a browser link and log in to your Azure account.</p> <ol> <li> <p>A browser window will open automatically, select Work or school account and click Next.</p> </li> <li> <p>Use the Username and Password found in the top section of the Resources tab in the lab environment.</p> </li> <li> <p>Select OK, then Done.</p> </li> </ol> </li> <li> <p>Then select the Default subscription from the command line.</p> </li> <li> <p>Once you've logged in, run the following command to assign the user role to the resource group:</p> <pre><code>$subId = $(az account show --query id --output tsv) `\n;$objectId = $(az ad signed-in-user show --query id -o tsv) `\n; az role assignment create --role \"f6c7c914-8db3-469d-8ca1-694a8f32e121\" --assignee-object-id $objectId --scope /subscriptions/$subId/resourceGroups/\"rg-agent-workshop\" --assignee-principal-type 'User'\n</code></pre> </li> <li> <p>Leave the terminal window open for the next steps.</p> </li> </ol>"},{"location":"includes/introduction-event/#open-the-workshop","title":"Open the Workshop","text":"<p>Follow these steps to open the workshop in Visual Studio Code:</p> Python <ol> <li> <p>From the terminal window, execute the following commands to clone the workshop repository, navigate to the relevant folder, set up a virtual environment, activate it, and install the required packages:</p> <pre><code>git clone https://github.com/microsoft/BUILD25-LAB331.git `\n; cd src `\n; python -m venv src/python/workshop/.venv `\n; src\\.venv\\Scripts\\activate `\n; pip install -r src/requirements.txt `\n</code></pre> </li> <li> <p>Open in VS Code. From the terminal window, run the following command:</p> <pre><code>code .vscode\\python-workspace.code-workspace\n</code></pre> <p>When the project opens in VS Code, two notifications appear in the bottom right corner. Click \u2716 to close both notifications.</p> </li> </ol>"},{"location":"includes/introduction-event/#project-connection-string","title":"Project Connection String","text":"<p>Next, we log in to Azure AI Foundry to retrieve the project connection string, which the agent app uses to connect to the Azure AI Agents Service.</p> <ol> <li>Navigate to the Azure AI Foundry website.</li> <li>Select Sign in and use the Username and Password found in the top section of the Resources tab in the lab environment. Click on the Username and Password fields to automatically fill in the login details.     </li> <li>Read the introduction to the Azure AI Foundry and click Got it.</li> <li> <p>Ensure you are on the AI Foundry home page. Click the AI Foundry tab in the top left corner.</p> <p></p> </li> <li> <p>Select the project name that starts with aip-.</p> <p></p> </li> <li> <p>Review the introduction guide and click Close.</p> </li> <li> <p>Locate the Project details section, click the Copy icon to copy the Project connection string.</p> <p></p> </li> </ol>"},{"location":"includes/introduction-event/#configure-the-workshop","title":"Configure the Workshop","text":"<pre><code>1. Switch back to the workshop you opened in VS Code.\n2. **Rename** the `.env.sample` file to `.env`.\n\n    - Select the **.env.sample** file in the VS Code **Explorer** panel.\n    - Right-click the file and select **Rename**, or press &lt;kbd&gt;F2&lt;/kbd&gt;.\n    - Change the file name to `.env` and press &lt;kbd&gt;Enter&lt;/kbd&gt;.\n\n3. Paste the **Project connection string** you copied from Azure AI Foundry into the `.env` file.\n\n    ```python\n    PROJECT_CONNECTION_STRING=\"&lt;your_project_connection_string&gt;\"\n    ```\n\n    Your `.env` file should look similar to this but with your project connection string.\n\n    ```python\n    MODEL_DEPLOYMENT_NAME=\"DeepSeek-R1\"\n    PROJECT_CONNECTION_STRING=\"&lt;your_project_connection_string&gt;\"\n    ```\n\n4. Save the `.env` file.\n</code></pre>"},{"location":"includes/introduction-event/#5-set-up-tavily-api","title":"5. Set Up Tavily API","text":"<pre><code>1. Register for a [Tavily API key](https://tavily.com/) to enable web search capabilities. This API is essential for the web research integration in Labs 2 and 3.\n\n2. Update the `.env` file in the project root with your Tavily API keys. Your file should now look like this:\n\n```\nAZURE_AI_ENDPOINT=your_azure_openai_endpoint\nAZURE_API_KEY=your_azure_openai_key\nTAVILY_API_KEY=your_tavily_api_key\n```\n</code></pre>"},{"location":"includes/introduction-event/#workshop-materials","title":"Workshop Materials","text":"<p>This workshop is designed as a progressive series of labs, each building on the previous one:</p> <ol> <li> <p>Lab 1 (Reasoning &amp; Model Thoughts): Learn how to stream the AI's thinking process in real-time and format final answers as bullet points.</p> </li> <li> <p>Lab 2 (Web Research Integration): Build a basic research system that generates queries, searches the web, and synthesizes the results.</p> </li> <li> <p>Lab 3 (Research Reflection): Extend the research capabilities with knowledge gap identification and iterative research cycles.</p> </li> <li> <p>Lab 4 (Launching Your Researcher): Deploy the research assistant as a web application with FastAPI and WebSockets for real-time updates.</p> </li> </ol> <p>Each lab includes code samples, explanations, and challenges to extend your learning.</p>"},{"location":"includes/introduction-event/#navigation","title":"Navigation","text":"<p>Use the navigation menu on the left to move between labs. Each lab includes:</p> <ul> <li>An overview of what you'll learn</li> <li>Prerequisites specific to that lab</li> <li>Detailed instructions with code samples</li> <li>Explanations of key components</li> <li>Challenges to extend your learning</li> <li>Next steps to progress through the workshop</li> </ul>"},{"location":"includes/introduction-event/#pro-tips","title":"Pro Tips","text":"<p>Tips</p> <ol> <li>The Burger Menu in the right-hand panel of the lab environment offers additional features, including the Split Window View and the option to end the lab. The Split Window View allows you to maximize the lab environment to full screen, optimizing screen space. The lab's Instructions and Resources panel will open in a separate window.</li> <li>If the lab instructions are slow to scroll in the lab environment, try copying the instructions\u2019 URL and opening it in your computer\u2019s local browser for a smoother experience.</li> <li>If you have trouble viewing an image, simply click the image to enlarge it.</li> </ol>"},{"location":"includes/introduction-self-guided/","title":"Introduction self guided","text":""},{"location":"includes/introduction-self-guided/#self-guided-learners","title":"Self-Guided Learners","text":"<p>These instructions are for self-guided learners who do not have access to a pre-configured lab environment. Follow these steps to set up your environment and begin the workshop.</p>"},{"location":"includes/introduction-self-guided/#introduction","title":"Introduction","text":"<p>This workshop is designed to teach you how to use Reasoning Models, like DeepSeek R1 and utilize tools and Reflection style architecture with LangChain to do deep research. It consists of multiple labs, each highlighting a specific feature of the process of building a deep researcher. The labs are meant to be completed in order, as each one builds on the knowledge and work from the previous lab.</p>"},{"location":"includes/introduction-self-guided/#prerequisites","title":"Prerequisites","text":"<ol> <li>Access to an Azure subscription. If you don't have an Azure subscription, create a free account before you begin.</li> <li>You need a GitHub account. If you don\u2019t have one, create it at GitHub.</li> </ol>"},{"location":"includes/introduction-self-guided/#open-the-workshop","title":"Open the Workshop","text":"<p>The preferred way to run this workshop is using GitHub Codespaces. This option provides a pre-configured environment with all the tools and resources needed to complete the workshop. Alternatively, you can open the workshop locally using a Visual Studio Code Dev Container.</p> GitHub Codespaces <p>Select Open in GitHub Codespaces to open the project in GitHub Codespaces.</p> <p></p> <p>Building the Codespace will take several minutes. You can continue reading the instructions while it builds.</p>"},{"location":"includes/introduction-self-guided/#authenticate-with-azure","title":"Authenticate with Azure","text":"<p>You need to authenticate with Azure so the agent app can access the Azure AI Agents Service and models. Follow these steps:</p> <ol> <li>Ensure the Codespace has been created.</li> <li>In the Codespace, open a new terminal window by selecting Terminal &gt; New Terminal from the VS Code menu.</li> <li> <p>Run the following command to authenticate with Azure:</p> <pre><code>az login --use-device-code\n</code></pre> <p>Note</p> <p>You'll be prompted to open a browser link and log in to your Azure account. Be sure to copy the authentication code first.</p> <ol> <li>A browser window will open automatically, select your account type and click Next.</li> <li>Sign in with your Azure subscription Username and Password.</li> <li>Paste the authentication code.</li> <li>Select OK, then Done.</li> </ol> <p>Warning</p> <p>If you have multiple Azure tenants, then you will need to select the appropriate tenant when authenticating.</p> <pre><code>az login --use-device-code --tenant &lt;tenant_id&gt;\n</code></pre> </li> <li> <p>Next, select the appropriate subscription from the command line.</p> </li> <li>Leave the terminal window open for the next steps.</li> </ol>"},{"location":"includes/introduction-self-guided/#deploy-the-azure-resources","title":"Deploy the Azure Resources","text":"<p>The following resources will be created in the <code>rg-deep-research-workshop</code> resource group in your Azure subscription.</p> <ul> <li>An Azure AI Foundry hub named deep-research-wksp</li> <li>An Azure AI Foundry project named Deep Research Workshop</li> <li>A Serverless (pay-as-you-go) DeepSeek R1 model deployment. See pricing details here.</li> </ul> <p>We have provided a bash script to automate the deployment of the resources required for the workshop. Alternatively, you may deploy resources manually using Azure AI Foundry studio. Select the desired tab.</p>"}]}